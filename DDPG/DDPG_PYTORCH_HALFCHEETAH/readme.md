the provided DDPG implementation is based on Lillicrap et al. (2015), not Gu et al. (2016).

The key difference is that Gu et al. (2016) proposed modifications to the original DDPG algorithm to improve sample efficiency, introducing algorithms like Normalized Advantage Functions (NAF) and utilizing Q-Prop for efficient policy optimization.

Key Points of Gu et al. (2016):
Paper: "Continuous Deep Q-Learning with Model-Based Acceleration"
(Paper Link)